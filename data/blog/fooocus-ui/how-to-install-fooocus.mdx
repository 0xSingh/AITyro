---
title: 'How to install Fooocus UI?'
date: '2023-12-16'
tags: ['stable-diffusion', 'fooocus-ui']
draft: false
summary: FooocusUI lets you concentrate on prompting, making it one of the best Stable Diffusion UIs for beginners. It keeps things simple with not too many distracting menus, and it comes with default styles, giving you a lot of freedom in your prompting.
---

![Fooocus UI](/static/images/blog/9.png)

**FooocusUI lets you concentrate on prompting, making it one of the best Stable Diffusion UIs for beginners. It keeps things simple with not too many distracting menus, and it comes with default styles, giving you a lot of freedom in your prompting.**

<TOCInline toc={props.toc} exclude="Introduction" />

If you wanna learn more about prompts then follow this üëâ How to master prompting in Stable Diffusion?

## Minimal System Requirements

- Python 3.10 ([Download Here](https://www.python.org/downloads/release/python-3100/))
- NVIDIA Card: CUDA required [12.1 recommended] (_[Download Now For Windows & Linux](https://developer.nvidia.com/cuda-12-1-0-download-archive)_)
- AMD Card: ROCm required for best result [ROCm 5.6 recommended. Checkout üëâ _[How to install ROCm](https://rocm.docs.amd.com/en/docs-5.6.0/deploy/windows/quick_start.html)_]

<table>
  <tbody>
    <tr>
      <td>
        <img
          src="/static/images/blog/logo-nvidia.png"
          alt="Nvidia Logo"
          style={{ width: '200px' }}
        />
      </td>
      <td>
        <img src="/static/images/blog/logo-radeon.webp" alt="AMD Logo" style={{ width: '200px' }} />
      </td>
    </tr>
    <tr>
      <td>
        Windows
        <ul>
          <li>
            <strong>Storage</strong>: 10 GB
          </li>
          <li>
            <strong>Ram</strong>: 8 GB
          </li>
          <li>
            <strong>VRAM</strong>: 4 GB
          </li>
        </ul>
      </td>
      <td>
        Windows
        <ul>
          <li>
            <strong>Storage</strong>: 10 GB
          </li>
          <li>
            <strong>Ram</strong>: 8 GB
          </li>
          <li>
            <strong>VRAM</strong>: 16 GB [DirectLM] <strong>OR</strong> 8 GB [ROCm]
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>
        Linux
        <ul>
          <li>
            <strong>Storage</strong>: 10 GB
          </li>
          <li>
            <strong>Ram</strong>: 8 GB
          </li>
          <li>
            <strong>VRAM</strong>: 4 GB
          </li>
        </ul>
      </td>
      <td>
        Linux
        <ul>
          <li>
            <strong>Storage</strong>: 10 GB
          </li>
          <li>
            <strong>Ram</strong>: 8 GB
          </li>
          <li>
            <strong>VRAM</strong>: 8 GB [ROCm]
          </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

## Installation

- To begin, select a location on your system. Once you‚Äôve decided, click on the top URL bar, and type in ‚Äú**cmd**‚Äù and hit **Enter**

![](/static/images/blog/10.png)

- Now, you need to clone the official Fooocus repository. To do this, run the following command in your CMD

```bash
git clone https://github.com/lllyasviel/Fooocus.git
```

- Now you need to create a Python virtual environment and then activate it, there are 2 ways of doing this.

<div className="pl-10">
1.  Using Conda ([Download Miniconda](https://docs.conda.io/projects/miniconda/en/latest/)):

```bash
conda create --name fooocus_venv python=3.10 -y
conda activate fooocus_venv
```

2. Using Python VENV

```bash
python -m venv fooocus_venv
fooocus_venv\Scripts\activate.bat
```

</div>

- Install Python dependencies

```bash
python -m pip install -r requirements_versions.txt
```

- For **CUDA 12.1** users (recommended)

```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

- _If you have **CUDA 11.8:**_

```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

AMD users are recommended to use Linux instead of Windows for the best results

- For **AMD ROCm** (5.6 is required)**:**

```bash
pip uninstall torch torchvision torchaudio torchtext functorch xformers
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
```

- We‚Äôre almost there! üòÅ Now, simply run this command, and it will start setting up Fooocus for you.

```bash
python entry_with_update.py
```

> Be patient; it will take some time for the first run, depending on your system and internet speed.

Some **Mac** M2 users may need to speed up model loading/unloading

- Try using this command instead. (Remember, the first run might take a significant amount of time depending on your internet speed.)

```bash
python entry_with_update.py --disable-offload-from-vram
```

**Once the first run is complete, it will automatically launch WebUI at:** [http://localhost:7865](http://localhost:7865/)

![](/static/images/blog/11.png)

> Hurray! it's done... Now you have your own personal text-to-image generator üòÑ

## Fooocus Result

Fooocus is the simplest of all UIs, but don‚Äôt underestimate its power. In Stable Diffusion, a good prompt can produce much better results than having a complex UI system. Here are a few examples that I created in under 5 minutes.

| ![2d Flat Cartoon](/static/images/blog/12.png) | ![Realistic](/static/images/blog/13.png)                 |
| ---------------------------------------------- | -------------------------------------------------------- |
| ![2d Flat Cartoon](/static/images/blog/14.png) | ![Cartoon With Water Colors](/static/images/blog/15.png) |

#### Struggling with Fooocus UI?

Check out this guide üëâ _**[How To Use Fooocus? A Brief Walkthrough With Some Helpful Tips And Tricks](https://aityro.com/fooocusui-walkthrough-with-some-helpful-tips-and-tricks)**_

## Does it work on MacOS?

M1 or M2 chip required to run Fooocus on MacOS.

## Does it work without GPU?

Absolutely! Even if you don‚Äôt have a GPU, you can still run it on your CPU. Just keep in mind that the render time will be significantly longer, and in the long run, it might impact the life expectancy of your CPU.

OR

You can use Google Colab as a workaround.

[![](https://aityro.com/wp-content/uploads/2023/12/colab-badge.svg)](https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb)
